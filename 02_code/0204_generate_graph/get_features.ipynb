{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f3e506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "import numpy as np\n",
    "alt.data_transformers.enable('data_server')\n",
    "alt.renderers.enable('default')\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification,load_iris\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "import pickle\n",
    "import sklearn.pipeline\n",
    "import xgboost as xgb\n",
    "import xmltodict\n",
    "\n",
    "# codes from https://github.com/gerritjandebruin/temporal-link-prediction/blob/main/src/get_features.py\n",
    "#. for temporal link prediction\n",
    "import collections\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import scipy.stats\n",
    "import typer\n",
    "\n",
    "import logger\n",
    "from progress_parallel import ProgressParallel, delayed\n",
    "\n",
    "app = typer.Typer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8686c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023531d6",
   "metadata": {},
   "source": [
    "### calculate temporal features with cn, jc, aa\n",
    "- codes revised from https://github.com/gerritjandebruin/temporal-link-prediction/blob/67b1eac9dd984a218be6603b254f0fe079c20c93/src/get_features.py\n",
    "- feature vector length == weighting functions * past event aggregation * topological feature==3 * 8 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15d664a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/yidesdo21/Projects/outputs/13_link_prediction/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2901cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_files = os.listdir(save_path)\n",
    "scores = dict()   # {score_file_name:a_list_of_scores, ...}\n",
    "\n",
    "for feature_file in feature_files:\n",
    "    if feature_file != \".DS_Store\":\n",
    "        with open(save_path+feature_file,\"rb\") as fp:  # uncpickling\n",
    "            f = pickle.load(fp)\n",
    "            scores[feature_file] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4467501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickling \n",
    "## X_res: for training data, sampled node pairs names, with 1:1 positive and negative labels\n",
    "## y_res: for training data, labels for the node pairs\n",
    "## X_res_tt: for testing data, sampled node pairs names, with 1:1 positive and negative labels\n",
    "## y_res_tt: for testing data, labels for the node pairs\n",
    "X_res,y_res,X_res_tt,y_res_tt = scores.get(\"x_res_gt_2019\"),scores.get(\"y_res_gt_2019\"),\\\n",
    "                                scores.get(\"x_res_tt_gt_2019\"),scores.get(\"y_res_tt_gt_2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40416f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_idx = scores.get(\"vertices_global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64e2703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metadata from the json\n",
    "meta_path = \"/Users/yidesdo21/Projects/outputs/12_time_slicing/metadata/\"\n",
    "\n",
    "with open(meta_path+\"articles_with_anno.json\") as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4312d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(save_path+\"cn_temp_gt_2019_sqrt_m3\",\"rb\") as fp:  # uncpickling\n",
    "#     f = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6d6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ffd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd10636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategies\n",
    "## codes revised from https://github.com/gerritjandebruin/temporal-link-prediction/blob/main/src/get_features.py\n",
    "def _rescale(x: pd.Series, *, lower_bound: float = 0.2) -> pd.Series:\n",
    "    \"\"\"_rescale the provided array.\n",
    "    Args:\n",
    "      lower_bound: Instead of normalizing between 0 and 1, normalize between \n",
    "        lower_bound and 1.\n",
    "    \"\"\"\n",
    "    lowest, highest = np.quantile(x, [0, 1])\n",
    "    return lower_bound + (1-lower_bound)*(x-lowest)/(highest-lowest)\n",
    "\n",
    "\n",
    "def _exp_time(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"Apply y=3*exp(x) and normalize it between (0,1).\"\"\"\n",
    "    return np.exp(3*x) / np.exp(3)\n",
    "\n",
    "\n",
    "def lin(x: pd.Series, lower_bound=.2):\n",
    "    return _rescale(_rescale(x.astype(int)), lower_bound=lower_bound)\n",
    "\n",
    "\n",
    "def exp(x: pd.Series, lower_bound=.2):\n",
    "    return _rescale(_exp_time(_rescale(x.astype(int))), lower_bound=lower_bound)\n",
    "\n",
    "\n",
    "def sqrt(x: pd.Series, lower_bound=.2):\n",
    "    return _rescale(np.sqrt(_rescale(x.astype(int))), lower_bound=lower_bound) #type: ignore\n",
    "\n",
    "\n",
    "TIME_STRATEGIES = {'lin': lin, 'exp': exp, 'sqrt': sqrt}\n",
    "\n",
    "AGGREGATION_STRATEGIES = {\n",
    "    'q0': np.min,\n",
    "    'q25': lambda array: np.quantile(array, .25),\n",
    "    'q50': np.median,\n",
    "    'q75': lambda array: np.quantile(array, .75),\n",
    "    'q100': np.max,\n",
    "    'm0': np.sum,\n",
    "    'm1': np.mean,\n",
    "    'm2': np.var,\n",
    "#     'm3': scipy.stats.skew,      #### m3,m4 is very slow\n",
    "#     'm4': scipy.stats.kurtosis\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc28029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b958f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instances(X_res,vertices):\n",
    "    \"\"\"create unconnected node pairs in the feature network and undersampled in the label network.,\n",
    "            1:1 pos:neg ratio, indices for nodes,\n",
    "       input: X_res -- 2D array of strings,\n",
    "            vertices -- {entity_name:entity_index}\n",
    "       output: instances -- a list of tuples\"\"\"\n",
    "    instances = list()\n",
    "    X_res_list = X_res.reshape(-1)\n",
    "    vertices_inv = dict((v,k) for k,v in vertices.items())  # {entity_index:entity_name}\n",
    "    \n",
    "    for node_pair in X_res_list:\n",
    "        idx1,idx2 = int(node_pair.split('::')[0]),int(node_pair.split('::')[1])\n",
    "        entity1,entity2 = vertices_inv.get(idx1),vertices_inv.get(idx2)           \n",
    "        instances.append((entity1,entity2))\n",
    "        \n",
    "    return instances\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06420650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edgelist_mature(metadata, t_max):\n",
    "    \"\"\"create a dataframe of entity1, entity2, and the time observed the links between two entities,\n",
    "        each (edge0,edge1,year) with different year stamp has to be stored in the edgelist,\n",
    "        input -- metadata, metadata for each article, \n",
    "              -- t_max, max year, inclusive,\n",
    "        output -- a dataframe with node pairs and the time stamp\n",
    "        \"\"\"\n",
    "    edge_year = list()   # all edges and year, (edge1,edge2,year), need duplications, for the weights\n",
    "\n",
    "    for m in metadata:   # the edges are on the citation level\n",
    "        year, db = int(m.get(\"year\")), m.get(\"sourcedb\")\n",
    "        \n",
    "        if year <= t_max:\n",
    "            if db == \"NLM\":\n",
    "                nio_uids = m.get(\"nio_uids\")\n",
    "                ptc_uids = m.get(\"ptc_uids\")\n",
    "\n",
    "                if nio_uids is not None and ptc_uids is not None:\n",
    "                    uids = sorted(nio_uids+ptc_uids)\n",
    "                    co_occur = list(combinations(uids, 2))\n",
    "                    for pair in co_occur:\n",
    "                        edge_year.append((pair[0],pair[1],year))\n",
    "                \n",
    "    edgelist_mature = pd.DataFrame(edge_year, columns=['source', 'target', 'datetime'])    \n",
    "    \n",
    "    return edgelist_mature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73231435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cn(info, instances, edgelist_mature, X_res,vertices=ver_idx, save_path=save_path):\n",
    "    \"\"\"calculated cn values without temporal information, the last timestamp for each link is used \n",
    "        input -- info -- saving information, e.g. \"cn_gt_2019\" \n",
    "                instances: negative cases,\n",
    "                 edgelist_mature: [node1,node2,datetime] dataframe,\n",
    "                 X_res: a list, sampled node pairs names, with 1:1 positive and negative labels                \n",
    "        output -- cn scores: a list of int, the length is number of unconnected node pairs (instances)\"\"\"\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(edgelist_mature[['source', 'target']])\n",
    "    scores = [len(list(nx.common_neighbors(G, u, v))) for u, v in instances]\n",
    "        \n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0755f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pa(info, instances, edgelist_mature, X_res,vertices=ver_idx, save_path=save_path):\n",
    "    G = nx.from_pandas_edgelist(edgelist_mature[['source', 'target']])\n",
    "    scores = [p for _, _, p in nx.preferential_attachment(G, instances)]\n",
    "    \n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "470c63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jc(info, instances, edgelist_mature, X_res,vertices=ver_idx, save_path=save_path):\n",
    "    \"\"\"calculated jc values without temporal information, the last timestamp for each link is used \n",
    "        input -- ... \n",
    "                X_res: a list, sampled node pairs names, with 1:1 positive and negative labels                \n",
    "        output -- jc scores: a list of int, the length is number of unconnected node pairs (instances)\"\"\"\n",
    "    G = nx.from_pandas_edgelist(edgelist_mature[['source', 'target']])\n",
    "    scores = [p for _, _, p in nx.jaccard_coefficient(G, instances)]\n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp)    \n",
    "    \n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "115c3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa(info, instances, edgelist_mature, X_res,vertices=ver_idx, save_path=save_path):\n",
    "    \"\"\"calculated aa values without temporal information, the last timestamp for each link is used \n",
    "        input -- ... \n",
    "                 X_res: a list, sampled node pairs names, with 1:1 positive and negative labels                \n",
    "        output -- aa scores: a list of int, the length is number of unconnected node pairs (instances)\"\"\"\n",
    "    graph_mature = nx.from_pandas_edgelist(edgelist_mature)\n",
    "    scores = [p for _, _, p in nx.adamic_adar_index(graph_mature, instances)]\n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp)  \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33ff3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cn_time_aware(info, instances, edgelist_mature, X_res, time_strategy,\n",
    "                  aggregation_strategy, vertices=ver_idx, save_path=save_path):\n",
    "    \"\"\"calculated cn values with weighted temporal information, \n",
    "        input -- ...\n",
    "                 X_res: a list, sampled node pairs names, with 1:1 positive and negative labels,\n",
    "                 vertices: {entity_name:entity_index},\n",
    "                 time _strategy: strategy used to weight time as the edge of the multigraph\n",
    "                 aggregation_strategy: strategy used to aggregate the edges for the same node pair in the multigraph,\n",
    "        output -- cn scores: a list of int, the length is number of unconnected node pairs (instances)\"\"\"\n",
    "        \n",
    "    df = edgelist_mature[['source', 'target', 'datetime']].assign(\n",
    "        datetime=lambda x: time_strategy(x['datetime'])\n",
    "    )\n",
    "    \n",
    "    # create a multigraph, it allows multiple edges between two entities\n",
    "    # G[u][z].values(), format: \n",
    "    #. multiple edges for one node pair are saved as a dictionary of dictionaries, {edge:{\"datetime\":...}, ...}\n",
    "    #.  ValuesView(AtlasView({0: {'datetime': 1.0000000000000002}, 1: {'datetime': 0.2}}))\n",
    "    G = nx.from_pandas_edgelist(df, create_using=nx.MultiGraph, edge_attr=True)\n",
    "    scores = list()\n",
    "    \n",
    "    for u, v in instances:\n",
    "        score = [\n",
    "            ## aggregation_strategy([e['datetime'] for e in G[u][z].values()])\n",
    "            # use the aggregation function on the multiple edges between the same pair of entities\n",
    "            ## aggregation_strategy([e['datetime'] for e in G[u][z].values()]) +\n",
    "            ## aggregation_strategy([e['datetime'] for e in G[v][z].values()])\n",
    "            # sum the aggregated results from (u,z) and (v,z) for (u,v)\n",
    "            aggregation_strategy([e['datetime'] for e in G[u][z].values()]) +\n",
    "            aggregation_strategy([e['datetime'] for e in G[v][z].values()])\n",
    "            # each common neighbour has to be summed for the score of (u,v)\n",
    "            for z in nx.common_neighbors(G, u, v)\n",
    "        ]\n",
    "        scores.append(sum(score))   \n",
    "        \n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp) \n",
    "        \n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "892ea9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pa_time_aware(info, instances, edgelist_mature, X_res, time_strategy,\n",
    "                  aggregation_strategy, vertices=ver_idx, save_path=save_path):\n",
    "    df = edgelist_mature[['source', 'target', 'datetime']].assign(\n",
    "        datetime=lambda x: time_strategy(x['datetime'])\n",
    "    )\n",
    "    G = nx.from_pandas_edgelist(df, create_using=nx.MultiGraph, edge_attr=True)\n",
    "\n",
    "    scores = list()\n",
    "    for u, v in instances:\n",
    "        all_u = [aggregation_strategy([e['datetime'] for e in G[u][a].values()])\n",
    "                 for a in G[u]]\n",
    "        all_v = [aggregation_strategy([e['datetime'] for e in G[v][b].values()])\n",
    "                 for b in G[v]]\n",
    "        scores.append(sum(all_u) * sum(all_v))\n",
    "        \n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp)    \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16215e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jc_time_aware(info, instances, edgelist_mature, X_res, time_strategy,\n",
    "                  aggregation_strategy, vertices=ver_idx, save_path=save_path):\n",
    "    \"\"\"calculated jc values with weighted temporal information, \n",
    "        input -- ...\n",
    "                 X_res: a list, sampled node pairs names, with 1:1 positive and negative labels,\n",
    "                 vertices: {entity_name:entity_index},\n",
    "                 time _strategy: strategy used to weight time as the edge of the multigraph\n",
    "                 aggregation_strategy: strategy used to aggregate the edges for the same node pair in the multigraph,\n",
    "        output -- jc scores: a list of int, the length is number of unconnected node pairs (instances)\"\"\"\n",
    "    \n",
    "   # logger.debug(f'Start converting edgelist.')\n",
    "#     print(\"start\")\n",
    "    df = edgelist_mature[['source', 'target', 'datetime']].assign(\n",
    "        datetime=lambda x: time_strategy(x['datetime'])\n",
    "    )\n",
    "    G = nx.from_pandas_edgelist(df, create_using=nx.MultiGraph, edge_attr=True)\n",
    "    \n",
    "#     print(\"build the graph\")\n",
    "    scores = list()\n",
    "\n",
    "#     print(\"start opening cn file\")\n",
    "#     with open(save_path+info.replace(\"jc\",\"cn\"),\"rb\") as fp:  # uncpickling\n",
    "#         f = pickle.load(fp)\n",
    "#     cnt = 0\n",
    "#     print(cnt)\n",
    "    \n",
    "    for u, v in instances:\n",
    "        # logger.debug('Get CN')\n",
    "        # already have cn scores\n",
    "        cn = [\n",
    "            aggregation_strategy([e['datetime'] for e in G[u][z].values()]) +\n",
    "            aggregation_strategy([e['datetime'] for e in G[v][z].values()])\n",
    "            for z in nx.common_neighbors(G, u, v)\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        # logger.debug('Get all activity of nodes')\n",
    "        all_u = [aggregation_strategy([e['datetime'] for e in G[u][a].values()])\n",
    "                 for a in G[u]]\n",
    "        all_v = [aggregation_strategy([e['datetime'] for e in G[v][b].values()])\n",
    "                 for b in G[v]]\n",
    "        all_activity = sum(all_u) + sum(all_v)\n",
    "        # logger.debug('Get score')\n",
    "        \n",
    "#         instance_cn = f[cnt]\n",
    "#         print(instance_cn)\n",
    "#         cnt += 1\n",
    "#         score = instance_cn / all_activity if all_activity != 0 else 0\n",
    "        score = sum(cn) / all_activity if all_activity != 0 else 0\n",
    "        scores.append(score)\n",
    "        \n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp) \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4e17849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_time_aware(info, instances, edgelist_mature, X_res, \n",
    "                  time_strategy, aggregation_strategy, vertices=ver_idx, save_path=save_path):\n",
    "    \"\"\"calculated aa values with weighted temporal information, \n",
    "        input -- ...\n",
    "                 X_res: a list, sampled node pairs names, with 1:1 positive and negative labels,\n",
    "                 vertices: {entity_name:entity_index},\n",
    "                 time _strategy: strategy used to weight time as the edge of the multigraph\n",
    "                 aggregation_strategy: strategy used to aggregate the edges for the same node pair in the multigraph,\n",
    "        output -- aa scores: a list of int, the length is number of unconnected node pairs (instances)\"\"\"    \n",
    "\n",
    "    df = edgelist_mature[['source', 'target', 'datetime']].assign(\n",
    "        datetime=lambda x: time_strategy(x['datetime'])\n",
    "    )\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(df, edge_attr=True, create_using=nx.MultiGraph)\n",
    "    \n",
    "    scores = list()\n",
    "    \n",
    "    for u, v in instances:\n",
    "        score = [\n",
    "            aggregation_strategy([e['datetime'] for e in G[u][z].values()]) *\n",
    "            aggregation_strategy([e['datetime'] for e in G[v][z].values()]) /\n",
    "            np.log(len(G[z]))\n",
    "            for z in nx.common_neighbors(G, u, v)\n",
    "        ]\n",
    "        scores.append(sum(score))\n",
    "        \n",
    "    with open(save_path+info, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores, fp)         \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec2259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7acb697",
   "metadata": {},
   "outputs": [],
   "source": [
    "## instances in the feature network of the training data\n",
    "## edges in the feature network of the training network\n",
    "instance_train = get_instances(X_res,vertices=ver_idx)\n",
    "edgelist_train = create_edgelist_mature(metadata, t_max=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91913956",
   "metadata": {},
   "outputs": [],
   "source": [
    "## instances in the feature network of the testing data\n",
    "## edges in the feature network of the testing network\n",
    "instance_test = get_instances(X_res_tt,vertices=ver_idx)\n",
    "edgelist_test = create_edgelist_mature(metadata, t_max=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f38e75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cn_scores = cn(\"cn_gt_2019\", instance_train, edgelist_train, X_res,vertices=ver_idx)\n",
    "# jc_scores = jc(\"jc_gt_2019\", instance_train, edgelist_train, X_res=X_res)\n",
    "# aa_scores = aa(\"aa_gt_2019\", instance_train, edgelist_train, X_res=X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "274ff9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa_score = pa(\"pa_gt_2019\", instance_train, edgelist_train, X_res=X_res)\n",
    "# pa_tt_scores = pa(\"pa_tt_gt_2019\", instance_test, edgelist_test, X_res=X_res_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9132720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cn_tt_scores = cn(\"cn_tt_gt_2019\", instance_test, edgelist_test, X_res=X_res_tt)\n",
    "# jc_tt_scores = jc(\"jc_tt_gt_2019\", instance_test, edgelist_test, X_res=X_res_tt)\n",
    "# aa_tt_scores = aa(\"aa_tt_gt_2019\", instance_test, edgelist_test, X_res=X_res_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04381965",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## 3*8*3, for the training network\n",
    "# for time_str, time_func in TIME_STRATEGIES.items():\n",
    "#     for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "#         if not os.path.exists(save_path+\"cn_temp_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "#             cn_temp_scores = cn_time_aware(\"cn_temp_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "#                                            instance_train, edgelist_train, X_res=X_res,\n",
    "#                                time_strategy=time_func,\n",
    "#                                aggregation_strategy=agg_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3bbdc1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q25 sqrt\n",
      "q50 sqrt\n",
      "q75 sqrt\n",
      "q100 sqrt\n",
      "m0 sqrt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8a1af89a8da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"jc_temp_gt_2019_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtime_str\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0magg_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             jc_temp_scores = jc_time_aware(\"jc_temp_gt_2019_\"+time_str+\"_\"+agg_str, \n\u001b[0m\u001b[1;32m      6\u001b[0m                                            \u001b[0minstance_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgelist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                \u001b[0mtime_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-7f5d6865c7d8>\u001b[0m in \u001b[0;36mjc_time_aware\u001b[0;34m(info, instances, edgelist_mature, X_res, time_strategy, aggregation_strategy, vertices, save_path)\u001b[0m\n\u001b[1;32m     38\u001b[0m         all_u = [aggregation_strategy([e['datetime'] for e in G[u][a].values()])\n\u001b[1;32m     39\u001b[0m                  for a in G[u]]\n\u001b[0;32m---> 40\u001b[0;31m         all_v = [aggregation_strategy([e['datetime'] for e in G[v][b].values()])\n\u001b[0m\u001b[1;32m     41\u001b[0m                  for b in G[v]]\n\u001b[1;32m     42\u001b[0m         \u001b[0mall_activity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_u\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-7f5d6865c7d8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m         all_u = [aggregation_strategy([e['datetime'] for e in G[u][a].values()])\n\u001b[1;32m     39\u001b[0m                  for a in G[u]]\n\u001b[0;32m---> 40\u001b[0;31m         all_v = [aggregation_strategy([e['datetime'] for e in G[v][b].values()])\n\u001b[0m\u001b[1;32m     41\u001b[0m                  for b in G[v]]\n\u001b[1;32m     42\u001b[0m         \u001b[0mall_activity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_u\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2248\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for time_str, time_func in TIME_STRATEGIES.items():\n",
    "    for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "        if not os.path.exists(save_path+\"jc_temp_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "            print(agg_str, time_str)\n",
    "            jc_temp_scores = jc_time_aware(\"jc_temp_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "                                           instance_train, edgelist_train, X_res=X_res,\n",
    "                               time_strategy=time_func,\n",
    "                               aggregation_strategy=agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "728cef62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0 <function amin at 0x7fe1d0f34b80>\n",
      "q25 <function <lambda> at 0x7fe05a98ab80>\n",
      "q50 <function median at 0x7fe1d10511f0>\n",
      "q75 <function <lambda> at 0x7fe05a98adc0>\n",
      "q100 <function amax at 0x7fe1d0f349d0>\n",
      "m0 <function sum at 0x7fe1d0f34160>\n",
      "m1 <function mean at 0x7fe1d0f35790>\n",
      "m2 <function var at 0x7fe1d0f35af0>\n"
     ]
    }
   ],
   "source": [
    "# for time_str, time_func in TIME_STRATEGIES.items():\n",
    "#     for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "#         if not os.path.exists(save_path+\"pa_temp_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "#             print(agg_str, agg_func)\n",
    "#             pa_temp_scores = pa_time_aware(\"pa_temp_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "#                                            instance_train, edgelist_train, X_res=X_res,\n",
    "#                                time_strategy=time_func,\n",
    "#                                aggregation_strategy=agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1edf4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6b3544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3*8*3, for the training network\n",
    "# for time_str, time_func in TIME_STRATEGIES.items():\n",
    "#     for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "#         if not os.path.exists(save_path+\"aa_temp_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "#             aa_temp_scores = aa_time_aware(\"aa_temp_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "#                                            instance_train, edgelist_train, X_res=X_res,\n",
    "#                                time_strategy=time_func,\n",
    "#                                aggregation_strategy=agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f5cbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3*8*3, for the testing network\n",
    "# for time_str, time_func in TIME_STRATEGIES.items():\n",
    "#     for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "#         if not os.path.exists(save_path+\"cn_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "#             cn_temp_scores_tt = cn_time_aware(\"cn_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "#                                               instance_test, edgelist_test, X_res=X_res_tt,\n",
    "#                                        time_strategy=time_func,\n",
    "#                                        aggregation_strategy=agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3*8*3, for the testing network\n",
    "for time_str, time_func in TIME_STRATEGIES.items():\n",
    "    for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "        print(agg_str, time_str)\n",
    "        if not os.path.exists(save_path+\"jc_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "            jc_temp_scores_tt = jc_time_aware(\"jc_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "                                              instance_test, edgelist_test, X_res=X_res_tt,\n",
    "                                       time_strategy=time_func,\n",
    "                                       aggregation_strategy=agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18e69455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3*8*3, for the testing network\n",
    "# for time_str, time_func in TIME_STRATEGIES.items():\n",
    "#     for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "#         if not os.path.exists(save_path+\"aa_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "#             aa_temp_scores_tt = aa_time_aware(\"aa_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "#                                               instance_test, edgelist_test, X_res=X_res_tt,\n",
    "#                                        time_strategy=time_func,\n",
    "#                                        aggregation_strategy=agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e4521ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0 exp\n",
      "q25 exp\n",
      "q50 exp\n",
      "q75 exp\n",
      "q100 exp\n",
      "m0 exp\n",
      "m1 exp\n",
      "m2 exp\n",
      "q0 sqrt\n",
      "q25 sqrt\n",
      "q50 sqrt\n",
      "q75 sqrt\n",
      "q100 sqrt\n",
      "m0 sqrt\n",
      "m1 sqrt\n",
      "m2 sqrt\n"
     ]
    }
   ],
   "source": [
    "# for time_str, time_func in TIME_STRATEGIES.items():\n",
    "#     for agg_str, agg_func in AGGREGATION_STRATEGIES.items():  \n",
    "#         if not os.path.exists(save_path+\"pa_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str):\n",
    "#             print(agg_str, time_str)\n",
    "#             pa_temp_scores = pa_time_aware(\"pa_temp_tt_gt_2019_\"+time_str+\"_\"+agg_str, \n",
    "#                                            instance_test, edgelist_test, X_res=X_res_tt,\n",
    "#                                time_strategy=time_func,\n",
    "#                                aggregation_strategy=agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b277be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
