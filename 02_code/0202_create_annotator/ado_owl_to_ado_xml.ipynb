{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ccd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Goal: 1) extract the <token, id, canonical, variants> triple from the ado.owl\n",
    "##       2) examine the concepts that are in the ado but not in the nio (this shouldn't be the case but it happens)\n",
    "##       3) merge the triples with the nio dictionary \n",
    "\n",
    "# the ado.owl structure: it has three different ontologies \n",
    "\n",
    "# # type 1: AlzheimerOntology\n",
    "#     <!-- http://scai.fraunhofer.de/AlzheimerOntology#amyloid_precursor_protein -->\n",
    "\n",
    "#     <owl:Class rdf:about=\"&AlzheimerOntology;amyloid_precursor_protein\">\n",
    "#         <rdfs:label>amyloid precursor protein</rdfs:label>\n",
    "#         <rdfs:subClassOf rdf:resource=\"&AlzheimerOntology;protein\"/>\n",
    "#         <NDDUO:Synonym>amyloid-beta protein precursor</NDDUO:Synonym>\n",
    "#         <NDDUO:Synonym>APP</NDDUO:Synonym>\n",
    "#         <NDDUO:Synonym>amyloid precursor-protein</NDDUO:Synonym>\n",
    "#     </owl:Class>\n",
    "\n",
    "## turn it into the format below: {token_id:[canonical]}, {token_id:[variants (don't include canonical here)]}\n",
    "# \t<token id=\"AlzheimerOntology:Prefrontal_cortex\" canonical=\"prefrontal cortex\">\n",
    "# \t\t<variant base=\"prefrontal cortices\"/>\n",
    "# \t\t<variant base=\"prefrontal cortex\"/>\n",
    "# \t</token>\n",
    "\n",
    "## type 2: NDDUO\n",
    "#     <!-- http://scai.fraunhofer.de/NDDUO#Epidemiological_study_type -->\n",
    "\n",
    "#     <owl:Class rdf:about=\"&NDDUO;Epidemiological_study_type\">\n",
    "#         <rdfs:label>Epidemiological study</rdfs:label>\n",
    "#         <rdfs:subClassOf rdf:resource=\"&span;Process\"/>\n",
    "#         <rdfs:subClassOf>\n",
    "#             <owl:Restriction>\n",
    "#                 <owl:onProperty rdf:resource=\"&NDDUO;is_entity_used_in\"/>\n",
    "#                 <owl:someValuesFrom rdf:resource=\"&NDDUO;epidemiology_context\"/>\n",
    "#             </owl:Restriction>\n",
    "#         </rdfs:subClassOf>\n",
    "#         <NDDUO:Synonym>Epidemiological studies</NDDUO:Synonym>\n",
    "#     </owl:Class>\n",
    "\n",
    "# \t<token id=\"NDDUO:Cluster\" canonical=\"cluster\">\n",
    "# \t\t<variant base=\"aggregation\"/>\n",
    "# \t\t<variant base=\"clustered\"/>\n",
    "# \t\t<variant base=\"cluster\"/>\n",
    "# \t</token>\n",
    "\n",
    "## type 3: bfo \n",
    "#     <!-- http://www.ifomis.org/bfo/1.1/span#TemporalInterval -->\n",
    "\n",
    "#     <owl:Class rdf:about=\"&span;TemporalInterval\">\n",
    "#         <rdfs:label rdf:datatype=\"&xsd;string\">temporal_interval</rdfs:label>\n",
    "#         <rdfs:subClassOf rdf:resource=\"&span;ConnectedTemporalRegion\"/>\n",
    "#         <rdfs:comment rdf:datatype=\"&xsd;string\">Definition: A connected temporal region [span:ConnectedTemporalRegion] lasting for more than a single moment of time.</rdfs:comment>\n",
    "#         <rdfs:comment rdf:datatype=\"&xsd;string\">Examples: any continuous temporal duration during which a process occurs</rdfs:comment>\n",
    "#     </owl:Class>\n",
    "\n",
    "# \t<token id=\"bfo:snap_DependentContinuant\" canonical=\"dependent_continuant\">\n",
    "# \t\t<variant base=\"dependent_continuant\"/>\n",
    "# \t</token>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049777a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # errors met: \n",
    "# # when using beautifulsoup the <findall> method, the <owl:Class> tag can also be included in the <owl:Class> tag\n",
    "# # exclude this situation by restraining the parents of <owl:Class> not being <owl:equivalentClass> or <rdfs:subClassOf>.\n",
    "#     <!-- http://scai.fraunhofer.de/AlzheimerOntology#NMDA_receptor_antagonist_drug_molecule -->\n",
    "\n",
    "#     <owl:Class rdf:about=\"&AlzheimerOntology;NMDA_receptor_antagonist_drug_molecule\">\n",
    "#         <rdfs:label>NMDA receptor antagonist drug molecule</rdfs:label>\n",
    "#         <owl:equivalentClass>\n",
    "#             <owl:Class>\n",
    "#                 <owl:intersectionOf rdf:parseType=\"Collection\">\n",
    "#                     <rdf:Description rdf:about=\"&NDDUO;Molecular_entities\"/>\n",
    "# ...\n",
    "#                 </owl:intersectionOf>\n",
    "#             </owl:Class>\n",
    "#         </owl:equivalentClass>\n",
    "# ...\n",
    "#     </owl:Class>\n",
    "\n",
    "#     <owl:Class rdf:about=\"&AlzheimerOntology;CCR2\">\n",
    "#         <rdfs:label>CCR2</rdfs:label>\n",
    "#         <rdfs:subClassOf rdf:resource=\"&AlzheimerOntology;Receptors\"/>\n",
    "#         <rdfs:subClassOf>\n",
    "#             <owl:Class>\n",
    "#                 <owl:intersectionOf rdf:parseType=\"Collection\">\n",
    "#                     <rdf:Description rdf:about=\"&AlzheimerOntology;chemokine\"/>\n",
    "# ...\n",
    "#                 </owl:intersectionOf>\n",
    "#             </owl:Class>\n",
    "#         </rdfs:subClassOf>\n",
    "#         <NDDUO:Synonym>CC chemokine receptor 2</NDDUO:Synonym>\n",
    "#     </owl:Class>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9496bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ado_path = \"/Users/yidesdo21/Projects/inputs/ontologies/Alzheimer Ontology v15R-xml_merged.owl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01f9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from xml.dom import minidom\n",
    "import xmltodict\n",
    "from collections import Counter, OrderedDict\n",
    "from collections.abc import Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0aad4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ado_path) as f:\n",
    "    contents = f.read()\n",
    "#     print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc22b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11df486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca3398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f451a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for owl_class in soup.find_all(\"owl:class\"):\n",
    "#     print(owl_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0757392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file\n",
    "xmldoc = minidom.Document()\n",
    "\n",
    "# creat root element\n",
    "root_element = xmldoc.createElement('synonym')\n",
    "xmldoc.appendChild(root_element)\n",
    "\n",
    "\n",
    "for owl_class in soup.find_all(\"owl:class\"):\n",
    "    if not owl_class.findParent('owl:equivalentclass') and not owl_class.findParent('rdfs:subclassof'):\n",
    "        rdf_about = owl_class[\"rdf:about\"].replace(\"&\", \"\")\n",
    "        ontology = rdf_about.split(\";\")[0]\n",
    "        token_id = rdf_about.replace(\";\", \":\")\n",
    "        \n",
    "        productChild = xmldoc.createElement('token')\n",
    "        productChild.setAttribute('id', token_id)  # attribute, value\n",
    "        \n",
    "        if child.name == \"NDDUO:Synonym\".lower():\n",
    "            print(child.name)\n",
    "            syno = child.get_text().lower()\n",
    "#             break\n",
    "            \n",
    "#         for child in owl_class.contents:\n",
    "#             variants = set()\n",
    "#             if child.name == \"rdfs:label\": \n",
    "#                 cano = child.get_text()\n",
    "#                 print(cano)\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4815d5c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# turn the first type AlzheimerOntology into the dictionary \n",
    "# I did two things here, these two methods to create the dictionary have the same outcome: \n",
    "# 1) create the xml dictioanry directly\n",
    "# 2) I also abide by the same format as the nio, because then it is \n",
    "#    easier to do the comparison and the following merging into the dictionary \n",
    "\n",
    "# id_cano = list()   # [(token_id, canonical), (...),]\n",
    "# id_syno = list()   # [(token_id1, synonym1), (token_id1, synonoym2), ...]\n",
    "\n",
    "# create file\n",
    "xmldoc = minidom.Document()\n",
    "\n",
    "# creat root element\n",
    "root_element = xmldoc.createElement('synonym')\n",
    "xmldoc.appendChild(root_element)\n",
    "\n",
    "\n",
    "for owl_class in soup.find_all(\"owl:class\"):\n",
    "    if not owl_class.findParent('owl:equivalentclass') and not owl_class.findParent('rdfs:subclassof'):\n",
    "        rdf_about = owl_class[\"rdf:about\"].replace(\"&\", \"\")\n",
    "        ontology = rdf_about.split(\";\")[0]\n",
    "        token_id = rdf_about.replace(\";\", \":\")\n",
    "        \n",
    "        productChild = xmldoc.createElement('token')\n",
    "        productChild.setAttribute('id', token_id)  # attribute, value\n",
    "\n",
    "        for child in owl_class.contents:\n",
    "            variants = set()\n",
    "            if child.name == \"rdfs:label\": \n",
    "                cano = child.get_text()\n",
    "#                 cano = child.get_text().lower()\n",
    "\n",
    "                if cano not in variants:   # avoid duplications in the variant base \n",
    "                    variants.add(cano)\n",
    "\n",
    "                    productChild.setAttribute('canonical', cano)\n",
    "                    root_element.appendChild(productChild)\n",
    "\n",
    "                    # create child element, the canonical also has to be in the variant\n",
    "                    product_grandChild = xmldoc.createElement('variant')\n",
    "\n",
    "                    # insert user data into element\n",
    "                    product_grandChild.setAttribute('base', cano)\n",
    "                    productChild.appendChild(product_grandChild) \n",
    "                \n",
    "#                 id_cano.append((token_id, cano))\n",
    "                \n",
    "            if child.name == \"NDDUO:Synonym\".lower():   # because beautifulsoup lowercase the children names\n",
    "                syno = child.get_text()\n",
    "#                 syno = child.get_text().lower()\n",
    "#                 print(syno)\n",
    "                \n",
    "                if syno not in variants:  # avoid duplications in the variant base\n",
    "                    variants.add(syno)\n",
    "                    \n",
    "                    # create child element\n",
    "                    product_grandChild = xmldoc.createElement('variant')\n",
    "\n",
    "                    # insert user data into element\n",
    "                    product_grandChild.setAttribute('base', syno)\n",
    "                    productChild.appendChild(product_grandChild)                  \n",
    "                \n",
    "#                 id_syno.append((token_id, syno))\n",
    "        \n",
    "xml_str = xmldoc.toprettyxml(indent =\"\\t\")\n",
    "\n",
    "# save file\n",
    "save_path_file = \"ado_case.xml\"\n",
    "dict_path = \"/Users/yidesdo21/Projects/inputs/dictionary/\"\n",
    "\n",
    "with open(dict_path+save_path_file, \"w\") as f:\n",
    "    f.write(xml_str)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_cano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad7da83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_syno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88954c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e42a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare ado.xml to nio*.xml\n",
    "xml_path = \"/Users/yidesdo21/Projects/inputs/dictionary/\"\n",
    "\n",
    "with open(xml_path+\"ado.xml\") as f:\n",
    "    ado_xml = f.read()\n",
    "    \n",
    "with open(xml_path+\"nio_iri_v3_3.xml\") as f:\n",
    "    nio_xml = f.read()\n",
    "\n",
    "ado_parsed = xmltodict.parse(ado_xml)\n",
    "nio_parsed = xmltodict.parse(nio_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceaa0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ado_dict = ado_parsed[\"synonym\"][\"token\"]\n",
    "nio_dict = nio_parsed[\"synonym\"][\"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3a7391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ADO concepts that are not in the NIO owl: 1087\n",
      "Number of ADO concepts that are in the NIO owl: 473\n",
      "Number of ADO concepts: 1560\n"
     ]
    }
   ],
   "source": [
    "ado_cnt, both_cnt = 0, 0\n",
    "for ado in ado_dict:\n",
    "    token_id = ado[\"@id\"].lower()\n",
    "#     print(token_id)\n",
    "    ado_cnt += 1\n",
    "    \n",
    "    for nio in nio_dict:\n",
    "        if nio[\"@id\"].lower() == token_id:\n",
    "#             print(nio)\n",
    "#             print(\"----------\")\n",
    "            both_cnt += 1\n",
    "\n",
    "print(\"Number of ADO concepts that are not in the NIO owl:\", ado_cnt-both_cnt)\n",
    "print(\"Number of ADO concepts that are in the NIO owl:\", both_cnt)\n",
    "print(\"Number of ADO concepts:\", ado_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281477f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are cases when the ADO concept and the NIO concept have the same token id\n",
    "## but they have different canonicals or different variants. \n",
    "## No need to process the ADO dictionary, because it can be processed when merging the dictionaries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "047b87c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "different in variants\n",
      "alzheimerontology:family_history\n",
      "nio: ['family history', 'family history risk factors']\n",
      "ado: ['family histories', 'family history', 'http://www.ebi.ac.uk/efo/efo_0000493']\n",
      "----------\n",
      "different in variants\n",
      "alzheimerontology:frontotemporal_dementia\n",
      "nio: [OrderedDict([('@base', 'dementia')]), OrderedDict([('@base', 'frontotemporal dementia')]), OrderedDict([('@base', 'frontotemporal lobar dementia')])]\n",
      "ado: OrderedDict([('@base', 'frontotemporal dementia')])\n",
      "----------\n",
      "different in variants\n",
      "alzheimerontology:cerebellar_cortex\n",
      "nio: ['cerebellar cortex', 'cerebellar cortices', 'cerebelo']\n",
      "ado: ['cerebellar cortex', 'cerebellar cortices']\n",
      "----------\n",
      "different in variants\n",
      "alzheimerontology:frontotemporal_dementia\n",
      "nio: OrderedDict([('@base', 'frontotemporal dementia')])\n",
      "ado: [OrderedDict([('@base', 'frontotemporal dementia')]), OrderedDict([('@base', 'dementia')]), OrderedDict([('@base', 'frontotemporal lobar dementia')])]\n",
      "----------\n",
      "different in canonical\n",
      "ndduo:prevalence\n",
      "nio: OrderedDict([('@id', 'NDDUO:prevalence'), ('@canonical', 'prevalence'), ('variant', OrderedDict([('@base', 'prevalence')]))])\n",
      "ado: OrderedDict([('@id', 'NDDUO:Prevalence'), ('@canonical', 'thing related to prevalence'), ('variant', [OrderedDict([('@base', 'thing related to prevalence')]), OrderedDict([('@base', 'prevalence')])])])\n",
      "----------\n",
      "different in variants\n",
      "ndduo:prevalence\n",
      "nio: OrderedDict([('@base', 'prevalence')])\n",
      "ado: [OrderedDict([('@base', 'thing related to prevalence')]), OrderedDict([('@base', 'prevalence')])]\n",
      "----------\n",
      "different in variants\n",
      "ndduo:gene\n",
      "nio: ['apoptosis-related gene', 'dna molecule region (fma)', 'gene', 'genes', 'stress gene']\n",
      "ado: ['apoptosis-related gene', 'gene', 'genes', 'stress gene']\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for ado in ado_dict:\n",
    "    token_id = ado[\"@id\"].lower()\n",
    "    \n",
    "    for nio in nio_dict:\n",
    "        if nio[\"@id\"].lower() == token_id:\n",
    "            ## compare the case when token ids are the same in two dictionaries, but the canonicals are different\n",
    "            if nio[\"@canonical\"] != ado[\"@canonical\"]:\n",
    "                print(\"different in canonical\")\n",
    "                print(token_id)\n",
    "                print(\"nio:\", nio)\n",
    "                print(\"ado:\", ado)\n",
    "                print(\"----------\")\n",
    "            \n",
    "#             print(type(nio[\"variant\"]), type(ado[\"variant\"]))\n",
    "#             print(isinstance(nio[\"variant\"], Mapping))\n",
    "#             print(nio[\"variant\"])\n",
    "\n",
    "            ## compare the case when token ids are the same in two dictionaries, but the variants are different\n",
    "            ## when type(nio[\"variant\"]) is not a list, i.e., is the OrderedDict, it means\n",
    "            ## the concept only have one variant. The same goes for the ado variants.\n",
    "            ## Then there are two cases: \n",
    "            ## 1) type(nio[\"variant\"]) == OrderedDict and type(ado[\"variant\"]) == OrderedDict ('collections.OrderedDict')\n",
    "            ## nio concept has one variant, and ado concept has one variant, then compare them directly,\n",
    "            ## 2) type(nio[\"variant\"]) == list and type(ado[\"variant\"]) == OrderedDict OR\n",
    "            ##    type(nio[\"variant\"]) == OrderedDict and type(ado[\"variant\"]) == list\n",
    "            ## one dictionary's concept and another has more than one concept, then no need to compare, they are different.\n",
    "            \n",
    "            \n",
    "            ## for the concepts that have only one variant, the nio and ado dictionaries are the same.\n",
    "            if isinstance(nio[\"variant\"], Mapping) and isinstance(ado[\"variant\"], Mapping):\n",
    "#                 print(nio[\"variant\"], ado[\"variant\"])\n",
    "                if nio[\"variant\"] != ado[\"variant\"]:\n",
    "                    print(\"different in variants\")\n",
    "                    print(token_id)\n",
    "                    print(\"nio:\", nio[\"variant\"])\n",
    "                    print(\"ado:\", ado[\"variant\"])\n",
    "            \n",
    "            if type(nio[\"variant\"]) != type(ado[\"variant\"]):\n",
    "                    print(\"different in variants\")\n",
    "                    print(token_id)\n",
    "                    print(\"nio:\", nio[\"variant\"])\n",
    "                    print(\"ado:\", ado[\"variant\"])\n",
    "                    print(\"----------\")\n",
    "            \n",
    "            \n",
    "            if type(nio[\"variant\"]) == list and type(ado[\"variant\"]) == list:\n",
    "#                 print(nio[\"variant\"])\n",
    "                nio_vars, ado_vars = list(), list()\n",
    "                for v in nio[\"variant\"]:\n",
    "                    nio_vars.append(v['@base'])\n",
    "                for v in ado[\"variant\"]:\n",
    "#                     print(ado[\"variant\"])\n",
    "                    ado_vars.append(v['@base'])\n",
    "#                 print(sorted(nio_vars) == sorted(ado_vars))\n",
    "                nio_variants, ado_variants = sorted(set(nio_vars)), sorted(set(ado_vars))\n",
    "                if nio_variants != ado_variants:\n",
    "                    print(\"different in variants\")\n",
    "                    print(token_id)\n",
    "                    print(\"nio:\", nio_variants)\n",
    "                    print(\"ado:\", ado_variants)\n",
    "#                 print(nio[\"variant\"])\n",
    "#                 print(ado[\"variant\"])\n",
    "#                 print(OrderedDict(sorted(nio[\"variant\"].iteritems(), key=lambda x: x[1]['@base'])))\n",
    "#                 print(OrderedDict(sorted(ado[\"variant\"].iteritems(), key=lambda x: x[1]['@base'])))\n",
    "                    print(\"----------\")\n",
    "#             nio_var, ado_var = sorted(nio[\"variant\"]), sorted(ado[\"variant\"])\n",
    "#             if nio_var != ado_var:\n",
    "#                 print(\"different in variants\")\n",
    "#                 print(\"nio:\", nio_var)\n",
    "#                 print(\"ado:\", ado_var)\n",
    "#                 print(\"----------\")\n",
    "                \n",
    "#             print(nio[\"variant\"], ado[\"variant\"])\n",
    "\n",
    "#             print(\"----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58447a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134ebf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4daa360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918ca9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891a6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
